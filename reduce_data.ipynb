{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotations folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 10000\n",
    "VAL_SIZE = 1000\n",
    "TEST_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data_path = 'dataset/reduced_data'\n",
    "  \n",
    "os.makedirs(reduced_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folders = ['bardata(1031)', 'clsdata(1031)', 'linedata(1028)', 'piedata(1008)']\n",
    "sub_folders = ['annotations', 'images']  \n",
    "image_sub_folders = ['train2019', 'val2019', 'test2019']\n",
    "\n",
    "sub_dir_map = {\n",
    "    main_folders[0]: \"bar\",\n",
    "    main_folders[1]: \"cls\",\n",
    "    main_folders[2]: \"line\",\n",
    "    main_folders[3]: \"pie\",\n",
    "}\n",
    "\n",
    "for main in main_folders:\n",
    "    parent_dir = os.path.join(reduced_data_path, main, sub_dir_map[main])\n",
    "\n",
    "    for sub in sub_folders:\n",
    "        sub_dir_path = os.path.join(parent_dir, sub)\n",
    "        os.makedirs(sub_dir_path, exist_ok=True) \n",
    "\n",
    "        if sub == \"images\":\n",
    "            for image_sub in image_sub_folders:\n",
    "                os.makedirs(os.path.join(sub_dir_path, image_sub), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_annotation(data, size):\n",
    "    reduced_data = {}\n",
    "    reduced_data['licenses'] = data['licenses']\n",
    "    reduced_data['images'] = []\n",
    "    reduced_data['annotations'] = []\n",
    "    reduced_data['categories'] = data['categories']\n",
    "\n",
    "    reduced_data['images'] = data['images'][:size]\n",
    "    image_ids = {img[\"id\"] for img in reduced_data['images']}   \n",
    "    reduced_data['annotations'] = [i for i in data['annotations'] if i['image_id'] in image_ids]\n",
    "\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset/data'\n",
    "output_path = 'dataset/reduced_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 44.9 s\n",
      "Wall time: 48.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    main_folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "    sub_folders = os.listdir(main_folder_path)\n",
    "\n",
    "    sub_folder = sub_folders[0] \n",
    "    sub_folder_path = os.path.join(main_folder_path, sub_folder)\n",
    "    annotations_path = os.path.join(sub_folder_path, \"annotations\")\n",
    "\n",
    "\n",
    "    output_annotations_path = os.path.join(output_path, folder, sub_folder, \"annotations\")\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            input_file = os.path.join(annotations_path, file_name)\n",
    "            output_file = os.path.join(output_annotations_path, file_name)\n",
    "\n",
    "            with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if \"train\" in file_name:\n",
    "                size = TRAIN_SIZE\n",
    "            elif \"val\" in file_name:\n",
    "                size = VAL_SIZE\n",
    "            elif \"test\" in file_name:\n",
    "                size = TEST_SIZE\n",
    "\n",
    "            reduced_json = reduced_annotation(data, size)\n",
    "\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(reduced_json, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(data, type, split):\n",
    "    image_filenames = {img[\"file_name\"] for img in data.get(\"images\", [])}\n",
    "\n",
    "    if type == 'bar':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/data/bardata(1031)/bar/images/train2019'\n",
    "            copy_path = 'dataset/reduced_data/bardata(1031)/bar/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/data/bardata(1031)/bar/images/val2019'\n",
    "            copy_path = 'dataset/reduced_data/bardata(1031)/bar/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/data/bardata(1031)/bar/images/test2019'\n",
    "            copy_path = 'dataset/reduced_data/bardata(1031)/bar/images/test2019'\n",
    "\n",
    "    elif type == 'pie':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/data/piedata(1008)/pie/images/train2019'\n",
    "            copy_path = 'dataset/reduced_data/piedata(1008)/pie/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/data/piedata(1008)/pie/images/val2019'\n",
    "            copy_path = 'dataset/reduced_data/piedata(1008)/pie/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/data/piedata(1008)/pie/images/test2019'\n",
    "            copy_path = 'dataset/reduced_data/piedata(1008)/pie/images/test2019'\n",
    "    \n",
    "    elif type == 'line':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/data/linedata(1028)/line/images/train2019'\n",
    "            copy_path = 'dataset/reduced_data/linedata(1028)/line/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/data/linedata(1028)/line/images/val2019'\n",
    "            copy_path = 'dataset/reduced_data/linedata(1028)/line/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/data/linedata(1028)/line/images/test2019'\n",
    "            copy_path = 'dataset/reduced_data/linedata(1028)/line/images/test2019'\n",
    "\n",
    "    elif type == 'cls':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/data/clsdata(1031)/cls/images/train2019'\n",
    "            copy_path = 'dataset/reduced_data/clsdata(1031)/cls/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/data/clsdata(1031)/cls/images/val2019'\n",
    "            copy_path = 'dataset/reduced_data/clsdata(1031)/cls/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/data/clsdata(1031)/cls/images/test2019'\n",
    "            copy_path = 'dataset/reduced_data/clsdata(1031)/cls/images/test2019'\n",
    "\n",
    "    copy_image_path = None  \n",
    "    copied_count = 0\n",
    "\n",
    "    for image_name in image_filenames:\n",
    "        src_image_path = os.path.join(src_path, image_name)\n",
    "        copy_image_path = os.path.join(copy_path, image_name)\n",
    "\n",
    "        if os.path.exists(src_image_path):  \n",
    "            shutil.copy2(src_image_path, copy_image_path)\n",
    "            copied_count += 1\n",
    "        else:\n",
    "            print(f\"Cannot found any images in: {src_image_path}\")\n",
    "\n",
    "    if copied_count > 0:\n",
    "        print(f\"{copied_count}/{len(image_filenames)} images copied to {copy_path}\\n\")\n",
    "    else:\n",
    "        print(f\"No images are copied to {copy_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar\n",
    "with open('dataset/reduced_data/bardata(1031)/bar/annotations/instancesBar(1031)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/bardata(1031)/bar/annotations/instancesBar(1031)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/bardata(1031)/bar/annotations/instancesBar(1031)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_test = json.load(f)\n",
    "\n",
    "# Pie\n",
    "with open('dataset/reduced_data/piedata(1008)/pie/annotations/instancesPie(1008)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/piedata(1008)/pie/annotations/instancesPie(1008)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/piedata(1008)/pie/annotations/instancesPie(1008)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_test = json.load(f)\n",
    "\n",
    "# Line\n",
    "with open('dataset/reduced_data/linedata(1028)/line/annotations/instancesLine(1023)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    line_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/linedata(1028)/line/annotations/instancesLine(1023)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    line_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/linedata(1028)/line/annotations/instancesLine(1023)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    line_test = json.load(f)\n",
    "\n",
    "# Cls\n",
    "with open('dataset/reduced_data/clsdata(1031)/cls/annotations/instancesCls(1031)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/clsdata(1031)/cls/annotations/instancesCls(1031)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/clsdata(1031)/cls/annotations/instancesCls(1031)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 images copied to dataset/reduced_data/bardata(1031)/bar/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/bardata(1031)/bar/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/bardata(1031)/bar/images/test2019\n",
      "\n",
      "10000/10000 images copied to dataset/reduced_data/piedata(1008)/pie/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/piedata(1008)/pie/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/piedata(1008)/pie/images/test2019\n",
      "\n",
      "10000/10000 images copied to dataset/reduced_data/linedata(1028)/line/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/linedata(1028)/line/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/linedata(1028)/line/images/test2019\n",
      "\n",
      "10000/10000 images copied to dataset/reduced_data/clsdata(1031)/cls/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/clsdata(1031)/cls/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/clsdata(1031)/cls/images/test2019\n",
      "\n",
      "CPU times: total: 36.8 s\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "copy_images(bar_train, 'bar', 'train')\n",
    "copy_images(bar_val, 'bar', 'val')\n",
    "copy_images(bar_test, 'bar', 'test')\n",
    "\n",
    "copy_images(pie_train, 'pie', 'train')\n",
    "copy_images(pie_val, 'pie', 'val')\n",
    "copy_images(pie_test, 'pie', 'test')\n",
    "\n",
    "copy_images(line_train, 'line', 'train')\n",
    "copy_images(line_val, 'line', 'val')\n",
    "copy_images(line_test, 'line', 'test')\n",
    "\n",
    "copy_images(cls_train, 'cls', 'train')\n",
    "copy_images(cls_val, 'cls', 'val')\n",
    "copy_images(cls_test, 'cls', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepRule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
