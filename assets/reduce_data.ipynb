{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "import shutil \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce data \n",
    "\n",
    "We try to reduce the data to (10000, 1000, 1000) for (train, val, test) of each folder. The reduced data saved to `./dataset/reduced_data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 10000\n",
    "VAL_SIZE = 1000\n",
    "TEST_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data_path = 'dataset/reduced_data'\n",
    "os.makedirs(reduced_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folders = ['bardata(1031)', 'clsdata(1031)', 'linedata(1028)', 'piedata(1008)']\n",
    "sub_folders = ['annotations', 'images']  \n",
    "image_sub_folders = ['train2019', 'val2019', 'test2019']\n",
    "\n",
    "sub_dir_map = {\n",
    "    main_folders[0]: \"bar\",\n",
    "    main_folders[1]: \"cls\",\n",
    "    main_folders[2]: \"line\",\n",
    "    main_folders[3]: \"pie\",\n",
    "}\n",
    "\n",
    "for main in main_folders:\n",
    "    parent_dir = os.path.join(reduced_data_path, main, sub_dir_map[main])\n",
    "\n",
    "    for sub in sub_folders:\n",
    "        sub_dir_path = os.path.join(parent_dir, sub)\n",
    "        os.makedirs(sub_dir_path, exist_ok=True) \n",
    "\n",
    "        if sub == \"images\":\n",
    "            for image_sub in image_sub_folders:\n",
    "                os.makedirs(os.path.join(sub_dir_path, image_sub), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a helper function to reduce data in bar, pie, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_annotation(data, size):\n",
    "    \"\"\" \n",
    "    Reduces the annotation data to the given size\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data to be reduced\n",
    "        size (int): The size to reduce the data to \n",
    "\n",
    "    Returns:\n",
    "        dict: The reduced data\n",
    "    \"\"\"\n",
    "    annotations_df = pd.DataFrame(data['annotations'])\n",
    "    images_df = pd.DataFrame(data['images'])    \n",
    "    \n",
    "    # Take the first size number of images\n",
    "    ids1 = images_df['id']\n",
    "    ids2 = annotations_df['image_id']\n",
    "\n",
    "    # Intersection of the two sets\n",
    "    ids = ids1[ids1.isin(ids2)]\n",
    "    ids = ids.sort_values()\n",
    "    ids = ids[:size]\n",
    "\n",
    "    # Filter the annotations based on the image ids\n",
    "    reduced_annotations = annotations_df[annotations_df['image_id'].isin(ids)]\n",
    "    reduced_images = images_df[images_df['id'].isin(ids)]\n",
    "    \n",
    "    data['images'] = json.loads(reduced_images.to_json(orient=\"records\"))\n",
    "    data['annotations'] = json.loads(reduced_annotations.to_json(orient=\"records\"))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another helper function to reduce data in cls (we can use the previous function but it just take 10000 bar data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_annotation_cls(data, size, RATES = [0.45, 0.33, 0.22]):\n",
    "    \"\"\"\n",
    "    Reduces the cls data to the given size \n",
    "    Keep the rate of 0 1 and 2 the same (0.45, 0.33, 0.22)\n",
    "    \n",
    "    Args:\n",
    "        data (dict): The data to be reduced\n",
    "        size (int): The size to reduce the data to \n",
    "\n",
    "    Returns:\n",
    "        dict: The reduced data\n",
    "    \"\"\"\n",
    "\n",
    "    annotations_df = pd.DataFrame(data['annotations'])\n",
    "    images_df = pd.DataFrame(data['images'])    \n",
    "\n",
    "    # Take each class index for images and annotations\n",
    "    cls0_image_ids = images_df[images_df['data_type'] == 0]['id']\n",
    "    cls1_image_ids = images_df[images_df['data_type'] == 1]['id']\n",
    "    cls2_image_ids = images_df[images_df['data_type'] == 2]['id']\n",
    "\n",
    "    cls0_annotation_ids = annotations_df[annotations_df['category_id'] == 0]['image_id']\n",
    "    cls1_annotation_ids = annotations_df[annotations_df['category_id'] == 1]['image_id']\n",
    "    cls2_annotation_ids = annotations_df[annotations_df['category_id'] == 2]['image_id']\n",
    "\n",
    "    # Take the intersection of image ids and annotation ids\n",
    "    cls0_ids = cls0_image_ids[cls0_image_ids.isin(cls0_annotation_ids)]\n",
    "    cls1_ids = cls1_image_ids[cls1_image_ids.isin(cls1_annotation_ids)]\n",
    "    cls2_ids = cls2_image_ids[cls2_image_ids.isin(cls2_annotation_ids)]\n",
    "\n",
    "    # Take the first size * RATE of the ids\n",
    "    reduced_cls0_ids = cls0_ids[:int(size * RATES[0])]\n",
    "    reduced_cls1_ids = cls1_ids[:int(size * RATES[1])]\n",
    "    reduced_cls2_ids = cls2_ids[:int(size * RATES[2])]\n",
    "\n",
    "    ids = pd.concat([reduced_cls0_ids, reduced_cls1_ids, reduced_cls2_ids])\n",
    "\n",
    "    # Filter the annotations based on the image ids\n",
    "    reduced_annotations = annotations_df[annotations_df['image_id'].isin(ids)]\n",
    "    reduced_images = images_df[images_df['id'].isin(ids)]\n",
    "\n",
    "    data['images'] = json.loads(reduced_images.to_json(orient=\"records\"))\n",
    "    \n",
    "    data['annotations'] = json.loads(reduced_annotations.to_json(orient=\"records\"))\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset/data'\n",
    "output_path = 'dataset/reduced_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 34s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for folder in os.listdir(data_path):\n",
    "    main_folder_path = os.path.join(data_path, folder)\n",
    "\n",
    "    # Check if it is a folder\n",
    "    if not os.path.isdir(main_folder_path):\n",
    "        continue\n",
    "\n",
    "    sub_folders = os.listdir(main_folder_path)\n",
    "\n",
    "    sub_folder = sub_folders[0] \n",
    "    sub_folder_path = os.path.join(main_folder_path, sub_folder)\n",
    "    annotations_path = os.path.join(sub_folder_path, \"annotations\")\n",
    "\n",
    "\n",
    "    output_annotations_path = os.path.join(output_path, folder, sub_folder, \"annotations\")\n",
    "\n",
    "    for file_name in os.listdir(annotations_path):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            input_file = os.path.join(annotations_path, file_name)\n",
    "            output_file = os.path.join(output_annotations_path, file_name)\n",
    "\n",
    "            with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if \"train\" in file_name:\n",
    "                size = TRAIN_SIZE\n",
    "            elif \"val\" in file_name:\n",
    "                size = VAL_SIZE\n",
    "            elif \"test\" in file_name:\n",
    "                size = TEST_SIZE\n",
    "\n",
    "            # Check startwith cls\n",
    "            if folder.startswith(\"cls\"):\n",
    "                reduced_json = reduced_annotation_cls(data, size)\n",
    "            else:\n",
    "                reduced_json = reduced_annotation(data, size)\n",
    "\n",
    "            with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(reduced_json, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(data, type, split):\n",
    "    \"\"\"\n",
    "    Copies the images from the original dataset to the reduced dataset\n",
    "\n",
    "    Args:\n",
    "        data (dict): The data containing the image filenames\n",
    "        type (str): The type of the data (bar, pie, line, cls)\n",
    "        split (str): The split of the data (train, val, test)\n",
    "    \"\"\"\n",
    "    image_filenames = {img[\"file_name\"] for img in data.get(\"images\", [])}\n",
    "\n",
    "    if type == 'bar':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/data/bardata(1031)/bar/images/train2019'\n",
    "            copy_path = 'dataset/reduced_data/bardata(1031)/bar/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/data/bardata(1031)/bar/images/val2019'\n",
    "            copy_path = 'dataset/reduced_data/bardata(1031)/bar/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/data/bardata(1031)/bar/images/test2019'\n",
    "            copy_path = 'dataset/reduced_data/bardata(1031)/bar/images/test2019'\n",
    "\n",
    "    elif type == 'pie':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/data/piedata(1008)/pie/images/train2019'\n",
    "            copy_path = 'dataset/reduced_data/piedata(1008)/pie/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/data/piedata(1008)/pie/images/val2019'\n",
    "            copy_path = 'dataset/reduced_data/piedata(1008)/pie/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/data/piedata(1008)/pie/images/test2019'\n",
    "            copy_path = 'dataset/reduced_data/piedata(1008)/pie/images/test2019'\n",
    "    \n",
    "    elif type == 'line':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/data/linedata(1028)/line/images/train2019'\n",
    "            copy_path = 'dataset/reduced_data/linedata(1028)/line/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/data/linedata(1028)/line/images/val2019'\n",
    "            copy_path = 'dataset/reduced_data/linedata(1028)/line/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/data/linedata(1028)/line/images/test2019'\n",
    "            copy_path = 'dataset/reduced_data/linedata(1028)/line/images/test2019'\n",
    "\n",
    "    elif type == 'cls':\n",
    "        if split == 'train':\n",
    "            src_path = 'dataset/data/clsdata(1031)/cls/images/train2019'\n",
    "            copy_path = 'dataset/reduced_data/clsdata(1031)/cls/images/train2019'\n",
    "        elif split == 'val':\n",
    "            src_path = 'dataset/data/clsdata(1031)/cls/images/val2019'\n",
    "            copy_path = 'dataset/reduced_data/clsdata(1031)/cls/images/val2019'\n",
    "        elif split == 'test':\n",
    "            src_path = 'dataset/data/clsdata(1031)/cls/images/test2019'\n",
    "            copy_path = 'dataset/reduced_data/clsdata(1031)/cls/images/test2019'\n",
    "\n",
    "    copy_image_path = None  \n",
    "    copied_count = 0\n",
    "\n",
    "    for image_name in image_filenames:\n",
    "        src_image_path = os.path.join(src_path, image_name)\n",
    "        copy_image_path = os.path.join(copy_path, image_name)\n",
    "\n",
    "        if os.path.exists(src_image_path):  \n",
    "            shutil.copy2(src_image_path, copy_image_path)\n",
    "            copied_count += 1\n",
    "        else:\n",
    "            print(f\"Cannot found any images in: {src_image_path}\")\n",
    "\n",
    "    if copied_count > 0:\n",
    "        print(f\"{copied_count}/{len(image_filenames)} images copied to {copy_path}\\n\")\n",
    "    else:\n",
    "        print(f\"No images are copied to {copy_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar\n",
    "with open('dataset/reduced_data/bardata(1031)/bar/annotations/instancesBar(1031)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/bardata(1031)/bar/annotations/instancesBar(1031)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/bardata(1031)/bar/annotations/instancesBar(1031)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    bar_test = json.load(f)\n",
    "\n",
    "# Pie\n",
    "with open('dataset/reduced_data/piedata(1008)/pie/annotations/instancesPie(1008)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/piedata(1008)/pie/annotations/instancesPie(1008)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/piedata(1008)/pie/annotations/instancesPie(1008)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    pie_test = json.load(f)\n",
    "\n",
    "# Line\n",
    "with open('dataset/reduced_data/linedata(1028)/line/annotations/instancesLine(1023)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    line_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/linedata(1028)/line/annotations/instancesLine(1023)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    line_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/linedata(1028)/line/annotations/instancesLine(1023)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    line_test = json.load(f)\n",
    "\n",
    "# Cls\n",
    "with open('dataset/reduced_data/clsdata(1031)/cls/annotations/instancesCls(1031)_train2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_train = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/clsdata(1031)/cls/annotations/instancesCls(1031)_val2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_val = json.load(f)\n",
    "\n",
    "with open('dataset/reduced_data/clsdata(1031)/cls/annotations/instancesCls(1031)_test2019.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    cls_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 images copied to dataset/reduced_data/bardata(1031)/bar/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/bardata(1031)/bar/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/bardata(1031)/bar/images/test2019\n",
      "\n",
      "10000/10000 images copied to dataset/reduced_data/piedata(1008)/pie/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/piedata(1008)/pie/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/piedata(1008)/pie/images/test2019\n",
      "\n",
      "10000/10000 images copied to dataset/reduced_data/linedata(1028)/line/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/linedata(1028)/line/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/linedata(1028)/line/images/test2019\n",
      "\n",
      "10000/10000 images copied to dataset/reduced_data/clsdata(1031)/cls/images/train2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/clsdata(1031)/cls/images/val2019\n",
      "\n",
      "1000/1000 images copied to dataset/reduced_data/clsdata(1031)/cls/images/test2019\n",
      "\n",
      "CPU times: total: 38.8 s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "copy_images(bar_train, 'bar', 'train')\n",
    "copy_images(bar_val, 'bar', 'val')\n",
    "copy_images(bar_test, 'bar', 'test')\n",
    "\n",
    "copy_images(pie_train, 'pie', 'train')\n",
    "copy_images(pie_val, 'pie', 'val')\n",
    "copy_images(pie_test, 'pie', 'test')\n",
    "\n",
    "copy_images(line_train, 'line', 'train')\n",
    "copy_images(line_val, 'line', 'val')\n",
    "copy_images(line_test, 'line', 'test')\n",
    "\n",
    "copy_images(cls_train, 'cls', 'train')\n",
    "copy_images(cls_val, 'cls', 'val')\n",
    "copy_images(cls_test, 'cls', 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
